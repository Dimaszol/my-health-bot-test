# gemini_analyzer.py - –û—á–∏—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

import os
import google.generativeai as genai
import asyncio
from PIL import Image
from typing import Tuple

class GeminiMedicalAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Gemini API"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å API –∫–ª—é—á–æ–º"""
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
        print("‚úÖ Gemini 1.5 Pro Latest –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def analyze_medical_image(self, image_path: str, lang: str = "ru", custom_prompt: str = None) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            lang: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ (ru, uk, en)
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
            
        Returns:
            Tuple[analysis_text, error_message]
        """
        try:
            print(f"\nüéì –û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ß–ï–†–ï–ó GEMINI:")
            print(f"üìÅ –§–∞–π–ª: {image_path}")
            print(f"üåê –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: {lang}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not os.path.exists(image_path):
                return "", f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path)
            print(f"üñºÔ∏è –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–∏—Ç—Ä—ã–π –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            prompt = custom_prompt or self._get_educational_prompt(lang)
            
            print(f"‚è≥ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
            
            # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            safety_settings = {
                genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
            }
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            response = await asyncio.to_thread(
                self.model.generate_content,
                [prompt, image],
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=4000,
                    candidate_count=1
                ),
                safety_settings=safety_settings
            )
            
            # –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            analysis_text = ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            if hasattr(response, 'text') and response.text:
                analysis_text = response.text
            elif hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason
                if hasattr(candidate, 'finish_reason'):
                    if candidate.finish_reason == 2:  # SAFETY
                        print("‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç...")
                        # –ü—Ä–æ–±—É–µ–º —Å –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
                        alt_prompt = self._get_alternative_prompt(lang)
                        response = await asyncio.to_thread(
                            self.model.generate_content,
                            [alt_prompt, image],
                            generation_config=genai.types.GenerationConfig(
                                temperature=0.2,
                                max_output_tokens=3000,
                                candidate_count=1
                            ),
                            safety_settings=safety_settings
                        )
                        
                        if hasattr(response, 'text') and response.text:
                            analysis_text = response.text
                        else:
                            return "", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
                            
                    elif candidate.finish_reason == 3:  # RECITATION
                        return "", "Gemini –æ–±–Ω–∞—Ä—É–∂–∏–ª –≤–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
                
                # –ï—Å–ª–∏ finish_reason –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
                if not analysis_text and hasattr(candidate, 'content') and candidate.content.parts:
                    try:
                        analysis_text = candidate.content.parts[0].text
                    except:
                        pass
            
            if not analysis_text:
                return "", "Gemini –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            
            print("\n" + "="*80)
            print("üéì –û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó GEMINI:")
            print("="*80)
            print(analysis_text[:300] + "..." if len(analysis_text) > 300 else analysis_text)
            print("="*80 + "\n")
            
            return analysis_text, ""
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ Gemini: {str(e)}"
            print(f"‚ùå {error_msg}")
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫
            if "finish_reason" in str(e) and "2" in str(e):
                return "", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            elif "The `response.text`" in str(e):
                return "", "Gemini –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ."
            else:
                return "", f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_msg}"
    
    def _get_educational_prompt(self, lang: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞
        response_language = {
            "ru": "Russian",
            "uk": "Ukrainian", 
            "en": "English"
        }.get(lang, "Russian")
        
        return f"""You are an experienced diagnostic doctor. Analyze medical images professionally and in detail.

IMPORTANT: Please respond in {response_language} language.

Analyze this medical image as a doctor:

1. **Type of study** - what is this (ECG, EEG, X-ray, MRI, ultrasound, tests, etc.)?

2. **Technical data** - visible patient parameters and settings

3. **Detailed findings** - what specifically is visible, measurements, indicators

4. **Pathological changes** - deviations from the norm, if any

5. **Diagnostic conclusion** - what this means clinically

6. **Recommendations** - what to do next, which doctor to consult

Be as specific and professional as possible. Indicate if a specialist consultation is needed.

IMPORTANT: Respond in {response_language} language."""

    def _get_alternative_prompt(self, lang: str) -> str:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        
        response_language = {
            "ru": "Russian",
            "uk": "Ukrainian", 
            "en": "English"
        }.get(lang, "Russian")
        
        return f"""Please describe what you observe in this image from an educational perspective. Focus on:

1. Technical aspects and image quality
2. Visible structures and patterns  
3. Any notable characteristics
4. Educational value for learning

This is for academic study purposes only.

IMPORTANT: Please respond in {response_language} language."""

# ‚úÖ –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –í –ü–†–û–ï–ö–¢–ï
async def send_to_gemini_vision(image_path: str, lang: str = "ru", prompt: str = None) -> Tuple[str, str]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        lang: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ (ru, uk, en)
        prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
        
    Returns:
        Tuple[analysis_result, error_message]
    """
    try:
        analyzer = GeminiMedicalAnalyzer()
        return await analyzer.analyze_medical_image(image_path, lang, prompt)
    except Exception as e:
        return "", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"