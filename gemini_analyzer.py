# gemini_analyzer.py - –û—á–∏—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

import os
import json
import google.generativeai as genai
import asyncio
from PIL import Image
from typing import Tuple, List, Dict

class GeminiMedicalAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Gemini API"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å API –∫–ª—é—á–æ–º"""
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("‚ùå GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
        print("‚úÖ Gemini 1.5 Pro Latest –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def analyze_medical_image(self, image_path: str, lang: str = "ru", custom_prompt: str = None) -> Tuple[str, str]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            lang: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ (ru, uk, en)
            custom_prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
            
        Returns:
            Tuple[analysis_text, error_message]
        """
        try:
            print(f"\nüéì –û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ß–ï–†–ï–ó GEMINI:")
            print(f"üìÅ –§–∞–π–ª: {image_path}")
            print(f"üåê –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: {lang}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not os.path.exists(image_path):
                return "", f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(image_path)
            print(f"üñºÔ∏è –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.size}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–∏—Ç—Ä—ã–π –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            prompt = custom_prompt or self._get_educational_prompt(lang)
            
            print(f"‚è≥ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
            
            # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            safety_settings = {
                genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
            }
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
            response = await asyncio.to_thread(
                self.model.generate_content,
                [prompt, image],
                generation_config=genai.types.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=5000,
                    candidate_count=1
                ),
                safety_settings=safety_settings
            )
            
            # –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            analysis_text = ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            if hasattr(response, 'text') and response.text:
                analysis_text = response.text
            elif hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º finish_reason
                if hasattr(candidate, 'finish_reason'):
                    if candidate.finish_reason == 2:  # SAFETY
                        print("‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç...")
                        # –ü—Ä–æ–±—É–µ–º —Å –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
                        alt_prompt = self._get_alternative_prompt(lang)
                        response = await asyncio.to_thread(
                            self.model.generate_content,
                            [alt_prompt, image],
                            generation_config=genai.types.GenerationConfig(
                                temperature=0.2,
                                max_output_tokens=3000,
                                candidate_count=1
                            ),
                            safety_settings=safety_settings
                        )
                        
                        if hasattr(response, 'text') and response.text:
                            analysis_text = response.text
                        else:
                            return "", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
                            
                    elif candidate.finish_reason == 3:  # RECITATION
                        return "", "Gemini –æ–±–Ω–∞—Ä—É–∂–∏–ª –≤–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
                
                # –ï—Å–ª–∏ finish_reason –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
                if not analysis_text and hasattr(candidate, 'content') and candidate.content.parts:
                    try:
                        analysis_text = candidate.content.parts[0].text
                    except:
                        pass
            
            if not analysis_text:
                return "", "Gemini –Ω–µ —Å–º–æ–≥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            
            print("\n" + "="*80)
            print("üéì –û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó GEMINI:")
            print("="*80)
            print(analysis_text)
            print("="*80 + "\n")
            
            return analysis_text, ""
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ Gemini: {str(e)}"
            print(f"‚ùå {error_msg}")
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –æ—à–∏–±–æ–∫
            if "finish_reason" in str(e) and "2" in str(e):
                return "", "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            elif "The `response.text`" in str(e):
                return "", "Gemini –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ."
            else:
                return "", f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_msg}"
    
    def _get_educational_prompt(self, lang: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —è–∑—ã–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞
        response_language = {
            "ru": "Russian",
            "uk": "Ukrainian", 
            "en": "English"
        }.get(lang, "Russian")
        
        return f"""You are an experienced diagnostic doctor. Analyze medical images professionally and in detail.

IMPORTANT: Please respond in {response_language} language.

First, determine what type of image this is:

**If this is a medical TEXT document** (medical records, lab results, prescriptions, discharge summaries, etc.) - transcribe ALL visible text EXACTLY as written, including:
- All numerical values with their units
- All reference ranges in parentheses  
- All medical terminology exactly as shown
- All handwritten notes
- Do NOT interpret, analyze, or change any medical assessments
- Do NOT add phrases like "within normal range" - copy the exact text
- Simply return what you see written

**If this is NOT a medical image** (photos, non-medical documents, random images) - respond: "This is not a medical image or document."

**If this is a medical IMAGING study** (ECG, EEG, X-ray, MRI, ultrasound, CT scan, etc.) - analyze it professionally:

1. **Type of study** - what is this?
2. **Technical data** - visible parameters and settings  
3. **Detailed findings** - what specifically is visible, measurements
4. **Pathological changes** - deviations from the norm, if any
5. **Diagnostic conclusion** - what this means clinically
6. **Recommendations** - what to do next, which doctor to consult

CRITICAL: For TEXT documents - be a transcriber, not a doctor. For IMAGING studies - be a doctor.

IMPORTANT: Respond in {response_language} language."""

    def _get_alternative_prompt(self, lang: str) -> str:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        
        response_language = {
            "ru": "Russian",
            "uk": "Ukrainian", 
            "en": "English"
        }.get(lang, "Russian")
        
        return f"""Please describe what you observe in this image from an educational perspective. Focus on:

1. Technical aspects and image quality
2. Visible structures and patterns  
3. Any notable characteristics
4. Educational value for learning

This is for academic study purposes only.

IMPORTANT: Please respond in {response_language} language."""

# ‚úÖ –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –í –ü–†–û–ï–ö–¢–ï
async def send_to_gemini_vision(image_path: str, lang: str = "ru", prompt: str = None) -> Tuple[str, str]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        lang: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ (ru, uk, en)
        prompt: –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
        
    Returns:
        Tuple[analysis_result, error_message]
    """
    try:
        analyzer = GeminiMedicalAnalyzer()
        return await analyzer.analyze_medical_image(image_path, lang, prompt)
    except Exception as e:
        return "", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"
    
async def extract_medical_timeline_gemini(document_text: str, existing_timeline: List[Dict], lang: str = "ru") -> List[Dict]:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π —á–µ—Ä–µ–∑ Gemini
    
    Args:
        document_text: –¢–µ–∫—Å—Ç –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        existing_timeline: –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–µ–¥–∫–∞—Ä—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π)
        lang: –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ (ru, uk, en)
    
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö/–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π
    """
    
    try:
        import google.generativeai as genai
        import os
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return []
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–µ–¥–∫–∞—Ä—Ç—É
        timeline_text = ""
        if existing_timeline:
            timeline_text = "\n".join([
                f"{entry['event_date']} | {entry['category']} | {entry['importance']} | \"{entry['description']}\""
                for entry in existing_timeline
            ])
        else:
            timeline_text = "–ú–µ–¥–∫–∞—Ä—Ç–∞ –ø—É—Å—Ç–∞—è"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞
        lang_names = {
            'ru': 'Russian',
            'uk': 'Ukrainian',
            'en': 'English'
        }
        response_lang = lang_names.get(lang, 'Russian')
        
        prompt = f"""You are a medical data extraction specialist. Extract key medical events from documents and update patient timeline.

TASK: Analyze the new document and update the medical timeline. Return ONLY changed/new entries or "NO_CHANGES".

RULES:
1. Extract dates from document text (if present) or use current date as fallback
2. Categories: diagnosis, treatment, test, procedure, general
3. Importance: critical (life-threatening), important (significant), normal (routine)  
4. Description: 10-20 words max, key medical facts only
5. If information duplicates existing timeline ‚Üí DON'T add
6. If information updates existing entry ‚Üí return updated version
7. Return ONLY valid JSON array or "NO_CHANGES"

OUTPUT FORMAT (JSON array):
[
  {{
    "event_date": "DD.MM.YYYY",
    "category": "diagnosis|treatment|test|procedure|general",
    "importance": "critical|important|normal", 
    "description": "Brief medical description"
  }}
]

EXISTING MEDICAL TIMELINE:
{timeline_text}

NEW DOCUMENT:
{document_text}

IMPORTANT: 
- Respond in {response_lang} language only
- Return ONLY JSON array or "NO_CHANGES" 
- NO explanations, NO additional text
- If no new medical information found, return "NO_CHANGES"

Extract and update medical timeline:"""

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Gemini
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,  # –ù–∏–∑–∫–∞—è –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                max_output_tokens=1500,
                candidate_count=1
            ),
            safety_settings=[
                {
                    "category": "HARM_CATEGORY_MEDICAL",
                    "threshold": "BLOCK_NONE"
                }
            ]
        )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        if not response.candidates:
            print("‚ö†Ô∏è Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞")
            return []
        
        result_text = ""
        for candidate in response.candidates:
            if hasattr(candidate, 'content') and candidate.content.parts:
                try:
                    result_text = candidate.content.parts[0].text.strip()
                    break
                except:
                    continue
        
        if not result_text:
            print("‚ö†Ô∏è Gemini –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return []
        
        print(f"üîÆ Gemini –æ—Ç–≤–µ—Ç: {result_text[:200]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ "NO_CHANGES"
        if result_text.upper() in ['NO_CHANGES', '–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô', '–ë–ï–ó_–ò–ó–ú–ï–ù–ï–ù–ò–ô']:
            print("üìã Gemini: –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –º–µ–¥–∫–∞—Ä—Ç–µ")
            return []
        
        # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å JSON
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–º–æ–≥—É—Ç –±—ã—Ç—å ``` –∏–ª–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è)
            json_start = result_text.find('[')
            json_end = result_text.rfind(']') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_text = result_text[json_start:json_end]
                events = json.loads(json_text)
                
                if isinstance(events, list):
                    print(f"üìã Gemini –∏–∑–≤–ª–µ–∫ {len(events)} –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π")
                    return events
                else:
                    print(f"‚ö†Ô∏è Gemini –≤–µ—Ä–Ω—É–ª –Ω–µ –º–∞—Å—Å–∏–≤: {result_text[:100]}")
                    return []
            else:
                print(f"‚ö†Ô∏è Gemini: JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ: {result_text[:200]}")
                return []
                
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è Gemini –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç: {result_text[:300]}")
            return []
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ–¥–∫–∞—Ä—Ç—ã —á–µ—Ä–µ–∑ Gemini: {e}")
        from error_handler import log_error_with_context
        log_error_with_context(e, {"function": "extract_medical_timeline_gemini"})
        return []