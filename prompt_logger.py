import logging
import json
from datetime import datetime
from typing import List, Dict, Tuple, Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
logger = logging.getLogger(__name__)

async def get_recent_messages_formatted(user_id: int, limit: int = 6) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ò–°–ö–õ–Æ–ß–ê–Ø —Ç–µ–∫—É—â–µ–µ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ) —Å–æ–æ–±—â–µ–Ω–∏–µ
    """
    try:
        from db_postgresql import get_last_messages
        
        # –ë–µ—Ä–µ–º –Ω–∞ 1 –±–æ–ª—å—à–µ —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ (—Ç–µ–∫—É—â–µ–µ) —Å–æ–æ–±—â–µ–Ω–∏–µ
        recent_messages = await get_last_messages(user_id, limit=limit + 1)
        
        if not recent_messages:
            return "No recent messages"
        
        # –ò–°–ö–õ–Æ–ß–ê–ï–ú –ü–û–°–õ–ï–î–ù–ï–ï –°–û–û–ë–©–ï–ù–ò–ï (—Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å)
        if len(recent_messages) > 1:
            recent_messages = recent_messages[:-1]  # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ
        
        # –û–ë–ï–°–ü–ï–ß–ò–í–ê–ï–ú –ß–ï–¢–ù–û–ï –ö–û–õ–ò–ß–ï–°–¢–í–û (–ø–∞—Ä—ã USER-BOT)
        if len(recent_messages) % 2 != 0:
            recent_messages = recent_messages[1:]  # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤–æ–µ –µ—Å–ª–∏ –Ω–µ—á–µ—Ç–Ω–æ–µ
        
        formatted_lines = []
        for msg in recent_messages:
            if isinstance(msg, (tuple, list)) and len(msg) >= 2:
                role = "USER" if msg[0] == 'user' else "BOT"
                content = str(msg[1])
                
                # –£–ú–ù–ê–Ø –û–ß–ò–°–¢–ö–ê HTML –¢–ï–ì–û–í
                import re
                content = re.sub(r'<[^>]+>', '', content)  # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
                
                # –û–ë–†–ï–ó–ö–ê –î–û 100 –°–ò–ú–í–û–õ–û–í –ë–ï–ó –†–ê–ó–†–´–í–ê –°–õ–û–í
                if len(content) > 100:
                    content = content[:97]
                    # –ù–∞–π–¥–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–æ–≤–æ
                    last_space = content.rfind(' ')
                    if last_space > 80:  # –ï—Å–ª–∏ –ø—Ä–æ–±–µ–ª –Ω–µ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ –∫ –Ω–∞—á–∞–ª—É
                        content = content[:last_space]
                    content += "..."
                
                formatted_lines.append(f"{role}: {content}")
        
        # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –î–û 3 –ü–ê–† (6 —Å–æ–æ–±—â–µ–Ω–∏–π)
        if len(formatted_lines) > 6:
            formatted_lines = formatted_lines[-6:]
        
        return "\n".join(formatted_lines) if formatted_lines else "No recent messages"
        
    except Exception as e:
        return "Recent messages unavailable"

async def get_medical_timeline_simple(user_id: int, limit: int = 6) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ–¥–∫–∞—Ä—Ç—ã –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º –≤–∏–¥–µ
    """
    try:
        from db_postgresql import get_db_connection, release_db_connection
        
        conn = await get_db_connection()
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏
        rows = await conn.fetch("""
            SELECT event_date, description, importance
            FROM medical_timeline 
            WHERE user_id = $1 
            ORDER BY event_date DESC, created_at DESC
            LIMIT $2
        """, user_id, limit)
        
        if not rows:
            return "Medical timeline: empty"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω–æ
        lines = []
        for row in rows:
            date_str = row['event_date'].strftime('%d.%m.%Y') if row['event_date'] else 'N/A'
            importance = row['importance'] or 'normal'
            description = (row['description'] or '')[:80]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
            emoji = 'üî¥' if importance == 'critical' else 'üü°' if importance == 'important' else '‚ö™'
            lines.append(f"{emoji} {date_str}: {description}")
        
        return "\n".join(lines)
        
    except Exception as e:
        return "Medical timeline: unavailable"
    finally:
        if 'conn' in locals():
            await release_db_connection(conn)

async def get_user_vector_count(user_id: int) -> int:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    try:
        from vector_db_postgresql import vector_db
        if not vector_db:
            return 0
            
        conn = await vector_db.db_pool.acquire()
        try:
            result = await conn.fetchval(
                "SELECT COUNT(*) FROM document_vectors WHERE user_id = $1", 
                user_id
            )
            return result or 0
        finally:
            await vector_db.db_pool.release(conn)
    except Exception as e:
        return 0

async def get_all_user_chunks(user_id: int, limit: int = 4) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –í–°–ï —á–∞–Ω–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö)
    """
    try:
        from vector_db_postgresql import vector_db
        if not vector_db:
            return []
            
        conn = await vector_db.db_pool.acquire()
        try:
            results = await conn.fetch("""
                SELECT 
                    dv.chunk_text,
                    dv.metadata,
                    dv.keywords,
                    d.title as document_title,
                    d.uploaded_at
                FROM document_vectors dv
                JOIN documents d ON d.id = dv.document_id
                WHERE dv.user_id = $1
                ORDER BY d.uploaded_at DESC
                LIMIT $2
            """, user_id, limit)
            
            chunks = []
            for row in results:
                try:
                    metadata = json.loads(row['metadata']) if row['metadata'] else {}
                except:
                    metadata = {}
                
                chunks.append({
                    "chunk_text": row['chunk_text'],
                    "metadata": metadata,
                    "keywords": row['keywords'],
                    "document_title": row['document_title'],
                    "uploaded_at": row['uploaded_at']
                })
            
            return chunks
        finally:
            await vector_db.db_pool.release(conn)
    except Exception as e:
        return []

async def process_user_question_detailed(user_id: int, user_input: str) -> Dict:
    """
    –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    
    –õ–æ–≥–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
    - 0 –≤–µ–∫—Ç–æ—Ä–æ–≤: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫
    - 1-4 –≤–µ–∫—Ç–æ—Ä–∞: –±–µ—Ä–µ–º –≤—Å–µ –±–µ–∑ –ø–æ–∏—Å–∫–∞  
    - 5+ –≤–µ–∫—Ç–æ—Ä–æ–≤: –¥–µ–ª–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫
    
    Returns:
        Dict —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
    """
    
    try:
        # –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã
        vector_count = await get_user_vector_count(user_id)
        
        # –®–ê–ì 2: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        try:
            from save_utils import format_user_profile
            profile_text = await format_user_profile(user_id)
        except Exception as e:
            profile_text = "–ü—Ä–æ—Ñ–∏–ª—å –ø–∞—Ü–∏–µ–Ω—Ç–∞ –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω"
        
        # –®–ê–ì 3: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        try:
            from db_postgresql import get_conversation_summary
            summary_text, _ = await get_conversation_summary(user_id)
            
            if not summary_text:
                summary_text = "–ù–æ–≤—ã–π –ø–∞—Ü–∏–µ–Ω—Ç, –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –±–µ—Å–µ–¥ –Ω–µ—Ç"
                
        except Exception as e:
            summary_text = "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"
        
        # –®–ê–ì 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)
        if vector_count == 0:
            # –ü—É—Å—Ç–∞—è –±–∞–∑–∞: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫
            chunks_text = "–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
            chunks_found = 0
            
        elif vector_count <= 4:
            # –ú–∞–ª–æ –≤–µ–∫—Ç–æ—Ä–æ–≤: –±–µ—Ä–µ–º –≤—Å–µ
            all_chunks = await get_all_user_chunks(user_id, limit=4)
            
            if all_chunks:
                chunk_texts = [chunk.get("chunk_text", "") for chunk in all_chunks if chunk.get("chunk_text", "").strip()]
                chunks_text = "\n\n".join(chunk_texts)
                chunks_found = len(chunk_texts)
            else:
                chunks_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"
                chunks_found = 0
                
        else:
            # –ú–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–≤: –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫
            try:
                # –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
                from gpt import enrich_query_for_vector_search, extract_keywords
                
                refined_query = await enrich_query_for_vector_search(user_input)
                keywords = await extract_keywords(user_input)
                
            except Exception as e:
                refined_query = user_input
                keywords = []
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
            try:
                from vector_db_postgresql import search_similar_chunks
                vector_chunks = await search_similar_chunks(user_id, refined_query, limit=10)
            except Exception as e:
                vector_chunks = []
            
            # –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            try:
                from vector_db_postgresql import keyword_search_chunks
                keyword_list_str = ", ".join(keywords) if keywords else user_input
                keyword_chunks = await keyword_search_chunks(user_id, keyword_list_str, limit=5)
            except Exception as e:
                keyword_chunks = []
            
            # –ì–∏–±—Ä–∏–¥–Ω–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
            try:
                from vector_db_postgresql import create_hybrid_ranking
                
                ranked_chunk_texts = create_hybrid_ranking(
                    vector_chunks=vector_chunks,
                    keyword_chunks=keyword_chunks,
                    boost_factor=1.8
                )
                
                selected_chunks = ranked_chunk_texts[:5]
                chunks_text = "\n\n".join(selected_chunks)
                chunks_found = len(selected_chunks)
                
            except Exception as e:
                # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
                vector_texts = [chunk.get("chunk_text", "") for chunk in vector_chunks[:3] if chunk.get("chunk_text", "").strip()]
                keyword_texts = [chunk.get("chunk_text", "") for chunk in keyword_chunks[:2] if chunk.get("chunk_text", "").strip()]
                all_chunks = list(dict.fromkeys(vector_texts + keyword_texts))
                chunks_text = "\n\n".join(all_chunks[:5])
                chunks_found = len(all_chunks)
        
        # –®–ê–ì 5: –ü–æ–ª—É—á–µ–Ω–∏–µ —è–∑—ã–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
        try:
            from db_postgresql import get_user_language
            lang = await get_user_language(user_id)
            
            system_prompt = (
                "You are a compassionate and knowledgeable virtual physician who guides the user through their medical journey. "
                "You speak in a friendly, human tone and provide explanations when needed. "
                f"Always respond in the '{lang}' language."
            )
            
        except Exception as e:
            system_prompt = "You are a helpful medical assistant."
            lang = 'ru'
        
        # –®–ê–ì 6: –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ–¥–∫–∞—Ä—Ç—ã
        try:
            medical_timeline = await get_medical_timeline_simple(user_id, limit=6)
        except Exception as e:
            medical_timeline = "Medical timeline: unavailable"
        
        # –®–ê–ì 7: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        try:
            recent_messages_text = await get_recent_messages_formatted(user_id, limit=6)
        except Exception as e:
            recent_messages_text = "Recent messages unavailable"

        # –®–ê–ì 8: –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
        user_prompt_parts = [            
            f"üìå Patient profile:\n{profile_text}",
            "",
            f"üß† Conversation summary:\n{summary_text}",
            "",
            f"üè• Medical timeline:\n{medical_timeline}",
            "",
            f"üîé Related historical data:\n{chunks_text or '–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}",
            "",
            f"üí¨ Recent messages (last 3 pairs):\n{recent_messages_text}",
            "",
            f"Patient: {user_input}"
        ]
        
        final_user_prompt = "\n".join(user_prompt_parts)
   
        return {
            "profile_text": profile_text,
            "summary_text": summary_text,
            "medical_timeline": medical_timeline,
            "recent_messages": recent_messages_text,
            "chunks_text": chunks_text or "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞",
            "chunks_found": chunks_found,
            "lang": lang,
            "context_text": final_user_prompt,
            "vector_count": vector_count
        }
        
    except Exception as e:
        from error_handler import log_error_with_context
        log_error_with_context(e, {
            "function": "process_user_question_detailed"
        })
        raise